{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqltPZC48uDG",
        "outputId": "549e49ee-5af1-4dc6-e005-45c4e83312a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daZ3l6Vq_Q2J",
        "outputId": "61c07f67-9366-4b34-817c-8e0c0f60e1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.20.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.15.2+cu118)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2022.10.31)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.65.0)\n",
            "Collecting huggingface-hub (from open_clip_torch)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from open_clip_torch)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (3.20.3)\n",
            "Collecting timm (from open_clip_torch)\n",
            "  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->open_clip_torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->open_clip_torch) (16.0.6)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (23.1)\n",
            "Collecting safetensors (from timm->open_clip_torch)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Installing collected packages: sentencepiece, safetensors, ftfy, huggingface-hub, timm, open_clip_torch\n",
            "Successfully installed ftfy-6.1.1 huggingface-hub-0.16.4 open_clip_torch-2.20.0 safetensors-0.3.2 sentencepiece-0.1.99 timm-0.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip install open_clip_torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import open_clip\n",
        "import os\n",
        "\n",
        "directory = '/content/drive/MyDrive/obj-images'\n",
        "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
        "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
        "\n",
        "images = torch.tensor([])\n",
        "files = []\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  f = os.path.join(directory, filename)\n",
        "  files.append(f)\n",
        "  img = preprocess(Image.open(f)).unsqueeze(0)\n",
        "  images = torch.cat((images, img), dim=0)\n",
        "\n",
        "text = tokenizer([\"a chicken flying over the cuckoo's nest\", \"a dog\", \"a cat\"])\n",
        "\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "  image_features = model.encode_image(images)\n",
        "  text_features = model.encode_text(text)\n",
        "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "  obj_img_probs = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
        "  # Get object indices\n",
        "  obj_list = torch.argmax(obj_img_probs, dim=1)\n",
        "\n",
        "print(\"List of object images: \", files)\n",
        "print(\"Label probs:\", obj_img_probs)\n",
        "print(\"List of primitive objects:\", obj_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqWNMbRw_bz2",
        "outputId": "a75b1446-7047-4c89-9575-54853bd4cf70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 1.9303,  1.9303,  1.9303,  ...,  1.9303,  1.9303,  1.9303],\n",
            "          [ 1.9303,  1.9303,  1.9303,  ...,  1.9303,  1.9303,  1.9303],\n",
            "          [ 1.9303,  1.9303,  1.9303,  ...,  1.9303,  1.9303,  1.9303],\n",
            "          ...,\n",
            "          [ 1.7990,  1.7990,  1.7990,  ...,  1.9303,  1.9303,  1.9303],\n",
            "          [ 1.7990,  1.7698,  1.7698,  ...,  1.9303,  1.9303,  1.9303],\n",
            "          [ 1.8135,  1.8135,  1.7844,  ...,  1.9303,  1.9303,  1.9303]],\n",
            "\n",
            "         [[ 2.0749,  2.0749,  2.0749,  ...,  2.0749,  2.0749,  2.0749],\n",
            "          [ 2.0749,  2.0749,  2.0749,  ...,  2.0749,  2.0749,  2.0749],\n",
            "          [ 2.0749,  2.0749,  2.0749,  ...,  2.0749,  2.0749,  2.0749],\n",
            "          ...,\n",
            "          [ 1.9098,  1.8948,  1.9098,  ...,  2.0749,  2.0749,  2.0749],\n",
            "          [ 1.8948,  1.8798,  1.8798,  ...,  2.0749,  2.0749,  2.0749],\n",
            "          [ 1.8948,  1.8948,  1.8798,  ...,  2.0749,  2.0749,  2.0749]],\n",
            "\n",
            "         [[ 2.1459,  2.1459,  2.1459,  ...,  2.1459,  2.1459,  2.1459],\n",
            "          [ 2.1459,  2.1459,  2.1459,  ...,  2.1459,  2.1459,  2.1459],\n",
            "          [ 2.1459,  2.1459,  2.1459,  ...,  2.1459,  2.1459,  2.1459],\n",
            "          ...,\n",
            "          [ 1.9326,  1.9326,  1.9326,  ...,  2.1459,  2.1459,  2.1459],\n",
            "          [ 1.9326,  1.9042,  1.9042,  ...,  2.1459,  2.1459,  2.1459],\n",
            "          [ 1.9326,  1.9184,  1.9042,  ...,  2.1459,  2.1459,  2.1459]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6457,  0.6457,  0.6457,  ...,  0.6019,  0.6019,  0.5873],\n",
            "          [ 0.6603,  0.6603,  0.6603,  ...,  0.6019,  0.5873,  0.5873],\n",
            "          [ 0.6603,  0.6603,  0.6603,  ...,  0.5873,  0.5873,  0.5873],\n",
            "          ...,\n",
            "          [-0.1718, -0.2010, -0.2156,  ...,  0.1055,  0.0325, -0.0550],\n",
            "          [-0.2302, -0.2448, -0.2448,  ...,  0.0033, -0.0550, -0.1134],\n",
            "          [-0.2448, -0.2448, -0.2448,  ..., -0.0405, -0.0988, -0.1134]],\n",
            "\n",
            "         [[ 1.0844,  1.0844,  1.0844,  ...,  0.9943,  0.9943,  0.9793],\n",
            "          [ 1.0994,  1.0994,  1.0994,  ...,  0.9943,  0.9793,  0.9793],\n",
            "          [ 1.0994,  1.0994,  1.0994,  ...,  0.9793,  0.9793,  0.9793],\n",
            "          ...,\n",
            "          [ 0.1389,  0.1089,  0.0939,  ...,  0.1539,  0.0488, -0.0712],\n",
            "          [ 0.1239,  0.1089,  0.1089,  ...,  0.2289,  0.1839,  0.0939],\n",
            "          [ 0.1089,  0.1089,  0.1089,  ...,  0.2740,  0.2589,  0.1839]],\n",
            "\n",
            "         [[ 0.2973,  0.2973,  0.2973,  ...,  0.2120,  0.2120,  0.1977],\n",
            "          [ 0.3115,  0.3115,  0.3115,  ...,  0.2120,  0.1977,  0.1977],\n",
            "          [ 0.3115,  0.3115,  0.3115,  ...,  0.1693,  0.1693,  0.1693],\n",
            "          ...,\n",
            "          [-0.5275, -0.5559, -0.5701,  ..., -0.4279, -0.5559, -0.6555],\n",
            "          [-0.5559, -0.5701, -0.5701,  ..., -0.4137, -0.4990, -0.5701],\n",
            "          [-0.5701, -0.5701, -0.5701,  ..., -0.3995, -0.4279, -0.4848]]],\n",
            "\n",
            "\n",
            "        [[[-0.7558, -0.7558, -0.7558,  ..., -0.7558, -0.7558, -0.7558],\n",
            "          [-0.7558, -0.7558, -0.7558,  ..., -0.7558, -0.7558, -0.7558],\n",
            "          [-0.7558, -0.7558, -0.7558,  ..., -0.7558, -0.7558, -0.7558],\n",
            "          ...,\n",
            "          [-0.7558, -0.7558, -0.7558,  ..., -0.7558, -0.7558, -0.7558],\n",
            "          [-0.7558, -0.7558, -0.7558,  ..., -0.7558, -0.7558, -0.7558],\n",
            "          [-0.7558, -0.7558, -0.7558,  ..., -0.7558, -0.7558, -0.7558]],\n",
            "\n",
            "         [[-0.6865, -0.6865, -0.6865,  ..., -0.6865, -0.6865, -0.6865],\n",
            "          [-0.6865, -0.6865, -0.6865,  ..., -0.6865, -0.6865, -0.6865],\n",
            "          [-0.6865, -0.6865, -0.6865,  ..., -0.6865, -0.6865, -0.6865],\n",
            "          ...,\n",
            "          [-0.6865, -0.6865, -0.6865,  ..., -0.6865, -0.6865, -0.6865],\n",
            "          [-0.6865, -0.6865, -0.6865,  ..., -0.6865, -0.6865, -0.6865],\n",
            "          [-0.6865, -0.6865, -0.6865,  ..., -0.6865, -0.6865, -0.6865]],\n",
            "\n",
            "         [[-0.4706, -0.4706, -0.4706,  ..., -0.4706, -0.4706, -0.4706],\n",
            "          [-0.4706, -0.4706, -0.4706,  ..., -0.4706, -0.4706, -0.4706],\n",
            "          [-0.4706, -0.4706, -0.4706,  ..., -0.4706, -0.4706, -0.4706],\n",
            "          ...,\n",
            "          [-0.4706, -0.4706, -0.4706,  ..., -0.4706, -0.4706, -0.4706],\n",
            "          [-0.4706, -0.4706, -0.4706,  ..., -0.4706, -0.4706, -0.4706],\n",
            "          [-0.4706, -0.4706, -0.4706,  ..., -0.4706, -0.4706, -0.4706]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8355,  0.8355,  0.8501,  ...,  0.8063,  0.8063,  0.8063],\n",
            "          [ 0.8501,  0.8647,  0.8792,  ...,  0.8063,  0.8063,  0.8063],\n",
            "          [ 0.8501,  0.8792,  0.8938,  ...,  0.8063,  0.8209,  0.8209],\n",
            "          ...,\n",
            "          [-0.8580, -0.8142, -0.9018,  ..., -0.1718, -0.2010, -0.1718],\n",
            "          [-0.7412, -0.8142, -0.9602,  ..., -0.1134, -0.1426, -0.4200],\n",
            "          [-0.6974, -0.8726, -0.9456,  ..., -0.0842,  0.0617,  0.0471]],\n",
            "\n",
            "         [[ 0.9343,  0.9343,  0.9493,  ...,  0.9043,  0.9043,  0.9043],\n",
            "          [ 0.9493,  0.9493,  0.9643,  ...,  0.9043,  0.9043,  0.9043],\n",
            "          [ 0.9493,  0.9493,  0.9643,  ...,  0.9043,  0.9193,  0.9193],\n",
            "          ...,\n",
            "          [-0.8967, -0.8666, -0.9417,  ..., -0.5965, -0.6565, -0.6565],\n",
            "          [-0.8366, -0.8816, -0.9867,  ..., -0.5815, -0.5665, -0.7766],\n",
            "          [-0.7916, -0.9267, -0.9717,  ..., -0.6115, -0.4164, -0.4014]],\n",
            "\n",
            "         [[ 1.1505,  1.1505,  1.1647,  ...,  1.1505,  1.1505,  1.1505],\n",
            "          [ 1.1647,  1.1789,  1.1932,  ...,  1.1505,  1.1505,  1.1505],\n",
            "          [ 1.1647,  1.1789,  1.1932,  ...,  1.1505,  1.1647,  1.1647],\n",
            "          ...,\n",
            "          [-0.7123, -0.6697, -0.7266,  ..., -0.5559, -0.6270, -0.5844],\n",
            "          [-0.6412, -0.6839, -0.7692,  ..., -0.5701, -0.5417, -0.6981],\n",
            "          [-0.5986, -0.7123, -0.7408,  ..., -0.5986, -0.4137, -0.4137]]],\n",
            "\n",
            "\n",
            "        [[[-1.3981, -1.3981, -1.3981,  ..., -1.3543, -1.3543, -1.3543],\n",
            "          [-1.3981, -1.3981, -1.3981,  ..., -1.3689, -1.3543, -1.3543],\n",
            "          [-1.3981, -1.3981, -1.3981,  ..., -1.3689, -1.3689, -1.3543],\n",
            "          ...,\n",
            "          [-1.1937, -1.1791, -1.2229,  ..., -1.4565, -1.4711, -1.4711],\n",
            "          [-1.2083, -1.3105, -1.3981,  ..., -1.4711, -1.4711, -1.4711],\n",
            "          [-1.2667, -1.3835, -1.2959,  ..., -1.4711, -1.4857, -1.4857]],\n",
            "\n",
            "         [[-1.4069, -1.3919, -1.3919,  ..., -1.3769, -1.3769, -1.3769],\n",
            "          [-1.4069, -1.4069, -1.4069,  ..., -1.3919, -1.3769, -1.3769],\n",
            "          [-1.4069, -1.4069, -1.4069,  ..., -1.3919, -1.3919, -1.3769],\n",
            "          ...,\n",
            "          [-1.2869, -1.2869, -1.3169,  ..., -1.4669, -1.4820, -1.4820],\n",
            "          [-1.3019, -1.3619, -1.4069,  ..., -1.4820, -1.4820, -1.4820],\n",
            "          [-1.3319, -1.4069, -1.3469,  ..., -1.4820, -1.4820, -1.4820]],\n",
            "\n",
            "         [[-1.1958, -1.1958, -1.1958,  ..., -1.1816, -1.1816, -1.1816],\n",
            "          [-1.1958, -1.1958, -1.1958,  ..., -1.1958, -1.1816, -1.1816],\n",
            "          [-1.1958, -1.1958, -1.1958,  ..., -1.1958, -1.1958, -1.1816],\n",
            "          ...,\n",
            "          [-1.1532, -1.1389, -1.1532,  ..., -1.2527, -1.2669, -1.2669],\n",
            "          [-1.1532, -1.1816, -1.2243,  ..., -1.2669, -1.2669, -1.2669],\n",
            "          [-1.1674, -1.2100, -1.1674,  ..., -1.2669, -1.2669, -1.2527]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8209,  0.8209,  0.8209,  ..., -0.3616, -0.3324, -0.3470],\n",
            "          [ 0.8063,  0.8063,  0.8063,  ..., -0.3324, -0.3324, -0.3324],\n",
            "          [ 0.8063,  0.8063,  0.8063,  ..., -0.3470, -0.3178, -0.3032],\n",
            "          ...,\n",
            "          [ 1.1858,  1.1274,  1.2296,  ...,  1.0690,  1.0836,  1.2004],\n",
            "          [ 1.2004,  1.1566,  1.0690,  ...,  0.9960,  0.9960,  1.1420],\n",
            "          [ 1.0544,  1.0252,  0.8938,  ...,  0.9960,  0.9668,  1.0106]],\n",
            "\n",
            "         [[ 0.6191,  0.6191,  0.6191,  ..., -0.5365, -0.5215, -0.5365],\n",
            "          [ 0.6041,  0.6041,  0.6041,  ..., -0.5965, -0.5815, -0.5965],\n",
            "          [ 0.6041,  0.6041,  0.6041,  ..., -0.7016, -0.6715, -0.6565],\n",
            "          ...,\n",
            "          [ 1.0694,  1.0093,  1.0994,  ...,  0.9493,  0.9793,  1.0994],\n",
            "          [ 1.0844,  1.0393,  0.9343,  ...,  0.8743,  0.8743,  1.0243],\n",
            "          [ 0.9343,  0.9043,  0.7542,  ...,  0.8743,  0.8442,  0.8893]],\n",
            "\n",
            "         [[ 0.3826,  0.3826,  0.3826,  ..., -0.5844, -0.5701, -0.5701],\n",
            "          [ 0.3684,  0.3684,  0.3684,  ..., -0.6128, -0.5986, -0.6128],\n",
            "          [ 0.3684,  0.3684,  0.3684,  ..., -0.6839, -0.6555, -0.6412],\n",
            "          ...,\n",
            "          [ 0.8661,  0.8092,  0.8803,  ...,  0.8377,  0.8519,  0.9656],\n",
            "          [ 0.8661,  0.8092,  0.7097,  ...,  0.7808,  0.7808,  0.9230],\n",
            "          [ 0.7239,  0.6812,  0.5390,  ...,  0.7808,  0.7523,  0.7950]]]])\n",
            "Label probs: tensor([[8.1209e-09, 1.0851e-09, 1.0000e+00, 2.6432e-06, 2.1583e-08, 5.5946e-08],\n",
            "        [5.4024e-05, 9.9926e-01, 6.4584e-04, 8.6608e-07, 3.3891e-05, 3.7175e-06],\n",
            "        [4.0467e-01, 5.3455e-07, 8.5076e-06, 5.7212e-09, 5.9237e-01, 2.9552e-03]])\n",
            "List of primitive objects: tensor([2, 1, 4])\n"
          ]
        }
      ]
    }
  ]
}